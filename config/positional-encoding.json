// training time of 30 sec on slurm
// 2 epochs * 30 img * 30**2 
{
    "network": {
        "n_layers": 8,
        "neurons_per_layer": 384
    },
    "encoding": {
        "otype": "Frequency",
        "n_frequencies": 8
    },
    "optim": {
        "training_epochs": 20,
        "loss": "L2",
        // TODO: fiddle with milestones to improve speed of convergence?
        "milestones": [],
        "gamma": 0.5,
        "batchsize": 1024,
        "samples_per_ray": 192,
        "learning_rate": 0.001,
        "pixel_importance_sampling": false,
        "random_seed": false,
        "interpolate_training_images": true
    },
    "data": {
        "dataset": "walnut",
        "transforms_file": "transforms",
        "ground_truth": "",
        "img_size": 40,
        "n_images": 10, 
        "noise_mean": 0,
        "noise_sd": 0,
    },
    "output": {
        "images": true,
        "slices": true,
        "samples_per_ray": 192,
        "slice_resolution": 200,
        "rays_per_pixel": 4,
        "hash_naming": true
    },
    "hardware": {
        "train": "cuda",
        "test": "cuda"
    }
}